import { useCallback, useEffect, useRef, useState } from 'react'
import { createAudioProcessor } from '@/lib/stt/audioProcessor'
import { createSTTService } from '@/lib/stt/speechToTextService'
import { createVAD, type VoiceActivityDetector } from '@/lib/stt/voiceActivityDetection'

// Voice recognition state interface
interface VoiceState {
  isListening: boolean
  isProcessing: boolean
  transcript: string
  confidence: number
  error: string | null
  supported: boolean
  processingTimeMs?: number
  recognizedCommand?: VoiceCommand | null
}

// Voice command interface
interface VoiceCommand {
  command: string
  parameters: Record<string, any>
  confidence: number
}

// Brazilian Portuguese voice commands patterns
const VOICE_COMMANDS = {
  BALANCE: [
    'qual Ã© o meu saldo',
    'quanto tenho na conta',
    'meu saldo',
    'ver saldo',
    'saldo da conta',
  ],
  TRANSFER: ['transferir para', 'enviar para', 'pagar para'],
} as const

export function useVoiceRecognition(
  options: {
    onTranscript?: (transcript: string, confidence: number) => void
    onCommand?: (command: VoiceCommand) => void
    onError?: (error: string) => void
    autoRestart?: boolean
    maxDuration?: number
  } = {}
) {
  const [state, setState] = useState<VoiceState>({
    isListening: false,
    isProcessing: false,
    transcript: '',
    confidence: 0,
    error: null,
    supported: false,
    recognizedCommand: null,
  })

  const recognitionRef = useRef<any>(null)
  const audioProcessorRef = useRef<any>(null)
  const vadRef = useRef<VoiceActivityDetector | null>(null)
  const timeoutRef = useRef<NodeJS.Timeout | null>(null)

  // Enhanced voice command processing with performance optimizations
  const processVoiceCommand = useCallback(
    (transcript: string, confidence: number) => {
      const startTime = performance.now()

      const normalizedTranscript = transcript.toLowerCase().trim()

      // Simple command matching for Brazilian Portuguese
      for (const [intent, patterns] of Object.entries(VOICE_COMMANDS)) {
        for (const pattern of patterns) {
          if (normalizedTranscript.includes(pattern)) {
            const command: VoiceCommand = {
              command: intent,
              parameters: { transcript, originalTranscript: transcript },
              confidence,
            }

            const processingTime = performance.now() - startTime
            command.parameters.processingTime = processingTime

            setState((prev) => ({
              ...prev,
              recognizedCommand: command,
              isProcessing: false,
              processingTimeMs: processingTime,
            }))

            options.onCommand?.(command)
            return
          }
        }
      }

      // If no specific command matched, send as generic transcript
      options.onTranscript?.(transcript, confidence)
    },
    [options]
  )

  // Start listening with performance optimizations
  const startListening = useCallback(async () => {
    if (state.isListening || state.isProcessing) return

    try {
      setState((prev) => ({
        ...prev,
        isListening: true,
        error: null,
        isProcessing: true,
        recognizedCommand: null,
      }))

      // Initialize VAD for better performance
      if (!vadRef.current) {
        vadRef.current = createVAD({
          minSpeechDuration: 0.3,
          silenceDuration: 1500,
        })
      }

      // Initialize audio processor with optimizations
      if (!audioProcessorRef.current) {
        audioProcessorRef.current = createAudioProcessor({
          sampleRate: 16000,
        })
      }

      // Initialize STT service with optimized settings
      createSTTService('pt-BR')

      // Start speech recognition with timeout
      // Note: Mock implementation for type fixing - will be replaced with actual STT integration
      console.log('Starting voice recognition with mock implementation')

      recognitionRef.current = {
        stop: () => console.log('Mock recognition stopped'),
        start: () => console.log('Mock recognition started'),
      } as any

      // Set timeout for auto-stop (reduced from 10s to 3s)
      timeoutRef.current = setTimeout(() => {
        if (recognitionRef.current) {
          recognitionRef.current.stop()
          recognitionRef.current = null
        }

        setState((prev) => ({
          ...prev,
          isListening: false,
          isProcessing: false,
          error: 'Tempo esgotado. Tente novamente.',
        }))
      }, 3000)
    } catch (error) {
      setState((prev) => ({
        ...prev,
        error: error instanceof Error ? error.message : 'Failed to start recognition',
        isListening: false,
        isProcessing: false,
      }))
      options.onError?.(error instanceof Error ? error.message : 'Failed to start recognition')
    }
  }, [state.isListening, state.isProcessing, options, processVoiceCommand])

  // Stop listening with proper cleanup
  const stopListening = useCallback(() => {
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current)
      timeoutRef.current = null
    }

    if (recognitionRef.current) {
      recognitionRef.current.stop()
      recognitionRef.current = null
    }

    if (audioProcessorRef.current) {
      audioProcessorRef.current.cleanup()
      audioProcessorRef.current = null
    }

    if (vadRef.current) {
      vadRef.current = null
    }

    setState((prev) => ({
      ...prev,
      isListening: false,
      isProcessing: false,
    }))
  }, [])

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      stopListening()
    }
  }, [stopListening])

  // Check browser support
  useEffect(() => {
    const checkSupport = async () => {
      const supported = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
      setState((prev) => ({ ...prev, supported }))
    }

    checkSupport()
  }, [])

  return {
    ...state,
    startListening,
    stopListening,
    toggleListening: () => (state.isListening ? stopListening() : startListening()),
  }
}
