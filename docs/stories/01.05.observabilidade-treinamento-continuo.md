# Story 01.05: Observabilidade e Treinamento Contínuo

## Status
**Current Status:** Draft  
**Epic:** 01 - Voice Interface Foundation  
**Priority:** Medium  
**Estimated Effort:** 3 days  
**Dependencies:** Data engineering, Customer success, Analytics stack

---

## Story

**As a** Product Manager do AegisWallet,  
**I want** um sistema completo de monitoramento e melhoria contínua da interface de voz,  
**so that** possamos manter alta acurácia, identificar problemas rapidamente e evoluir o sistema baseado no feedback real dos usuários.

---

## Acceptance Criteria

1. [ ] Dashboard com métricas de acurácia, latência e abandono
2. [ ] Coleta de feedback in-app após comandos críticos
3. [ ] Ferramenta interna para revisão de áudios (com consentimento) e rotulagem
4. [ ] Automatização de re-treinamento semanal com novas frases
5. [ ] Playbook de incidentes (queda de acurácia, falha de provedor)
6. [ ] Alertas automáticos para métricas abaixo do threshold
7. [ ] Relatórios semanais de performance para stakeholders
8. [ ] Sistema de A/B testing para melhorias de voz

---

## Tasks / Subtasks

- [ ] **Dashboard de Métricas em Tempo Real** (AC: 1)
  - [ ] Criar dashboard com métricas de acurácia por comando
  - [ ] Implementar tracking de latência end-to-end
  - [ ] Adicionar métricas de abandono e retry
  - [ ] Configurar visualizações por região/sotaque
  - [ ] Implementar alertas visuais para degradação

- [ ] **Sistema de Feedback do Usuário** (AC: 2)
  - [ ] Implementar coleta de feedback pós-comando
  - [ ] Criar interface de rating (1-5 estrelas) não intrusiva
  - [ ] Adicionar opção de feedback textual opcional
  - [ ] Configurar triggers para comandos críticos
  - [ ] Implementar analytics de satisfação

- [ ] **Ferramenta de Revisão e Rotulagem** (AC: 3)
  - [ ] Criar interface interna para revisão de áudios
  - [ ] Implementar sistema de rotulagem colaborativa
  - [ ] Adicionar controles de privacidade e consentimento
  - [ ] Configurar workflow de aprovação para rotulações
  - [ ] Implementar export de datasets para treinamento

- [ ] **Automatização de Re-treinamento** (AC: 4)
  - [ ] Configurar pipeline de re-treinamento semanal
  - [ ] Implementar validação automática de novos modelos
  - [ ] Criar sistema de rollback para modelos com baixa performance
  - [ ] Adicionar versionamento de modelos de voz
  - [ ] Configurar deploy automático após validação

- [ ] **Playbooks e Gestão de Incidentes** (AC: 5, 6)
  - [ ] Criar playbook para queda de acurácia
  - [ ] Documentar procedimentos para falha de provedor
  - [ ] Implementar alertas automáticos por Slack/email
  - [ ] Configurar escalation automático para incidentes críticos
  - [ ] Criar runbooks para problemas comuns

- [ ] **Relatórios e A/B Testing** (AC: 7, 8)
  - [ ] Implementar relatórios semanais automatizados
  - [ ] Criar sistema de A/B testing para melhorias
  - [ ] Configurar segmentação de usuários para testes
  - [ ] Implementar análise estatística de resultados
  - [ ] Adicionar dashboard executivo com KPIs

---

## Dev Notes

### Arquitetura Relevante

**Estrutura Atual:**
- `src/hooks/useVoiceRecognition.ts` - Hook com métricas básicas
- `src/lib/voiceCommandProcessor.ts` - Processador com logging
- `supabase/` - Database para armazenamento de métricas

**Novos Arquivos Necessários:**
- `src/lib/analytics/voiceMetrics.ts` - Coleta de métricas
- `src/lib/analytics/feedbackCollector.ts` - Sistema de feedback
- `src/components/admin/VoiceDashboard.tsx` - Dashboard interno
- `src/components/feedback/VoiceFeedback.tsx` - Interface de feedback
- `src/lib/ml/modelManager.ts` - Gerenciamento de modelos

**Schema do Supabase:**
```sql
-- Tabela para métricas de voz
CREATE TABLE voice_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id),
  session_id UUID,
  command_type TEXT,
  transcript TEXT,
  confidence_score DECIMAL(3,2),
  processing_time_ms INTEGER,
  success BOOLEAN,
  error_type TEXT,
  user_region TEXT,
  device_type TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Tabela para feedback do usuário
CREATE TABLE voice_feedback (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES auth.users(id),
  metric_id UUID REFERENCES voice_metrics(id),
  rating INTEGER CHECK (rating >= 1 AND rating <= 5),
  feedback_text TEXT,
  feedback_type TEXT CHECK (feedback_type IN ('accuracy', 'speed', 'understanding', 'general')),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Tabela para rotulagem de áudios
CREATE TABLE audio_labels (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  metric_id UUID REFERENCES voice_metrics(id),
  labeler_id UUID REFERENCES auth.users(id),
  correct_transcript TEXT,
  intent_label TEXT,
  quality_score INTEGER CHECK (quality_score >= 1 AND quality_score <= 5),
  notes TEXT,
  approved BOOLEAN DEFAULT false,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Tabela para modelos de voz
CREATE TABLE voice_models (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  version TEXT NOT NULL,
  model_type TEXT NOT NULL,
  training_data_hash TEXT,
  accuracy_score DECIMAL(5,4),
  latency_p95_ms INTEGER,
  is_active BOOLEAN DEFAULT false,
  deployed_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);

-- Tabela para experimentos A/B
CREATE TABLE voice_experiments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name TEXT NOT NULL,
  description TEXT,
  variant_a_config JSONB,
  variant_b_config JSONB,
  user_allocation JSONB, -- Mapeamento user_id -> variant
  start_date TIMESTAMP WITH TIME ZONE,
  end_date TIMESTAMP WITH TIME ZONE,
  status TEXT CHECK (status IN ('draft', 'running', 'completed', 'cancelled')),
  results JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT now()
);
```

### Métricas e KPIs

**Métricas Principais:**
- Acurácia de reconhecimento por comando
- Latência end-to-end (STT + NLU + resposta)
- Taxa de abandono por etapa
- Satisfação do usuário (NPS de voz)
- Taxa de re-tentativas por comando

**Alertas Configurados:**
- Acurácia <90% por 15 minutos
- Latência p95 >1 segundo por 10 minutos
- Taxa de erro >5% por 5 minutos
- Queda de 20% em qualquer métrica

### Testing

**Localização:** `src/test/analytics/voice/`
**Frameworks:** Vitest para lógica, Playwright para dashboards
**Cenários de Teste:**
- Coleta precisa de métricas
- Funcionamento de alertas
- Interface de feedback responsiva
- Pipeline de re-treinamento
- Dashboards com dados reais

**Validação de Dados:**
- Integridade de métricas coletadas
- Precisão de cálculos estatísticos
- Performance de queries analíticas
- Segurança de dados sensíveis

### Configurações de Monitoramento

**Dashboards Principais:**
1. **Operational Dashboard**: Métricas em tempo real
2. **Quality Dashboard**: Acurácia e satisfação
3. **Performance Dashboard**: Latência e throughput
4. **Business Dashboard**: KPIs executivos

**Alertas por Canal:**
- Slack: Alertas operacionais
- Email: Relatórios semanais
- PagerDuty: Incidentes críticos
- In-app: Notificações para equipe

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-04 | 1.0.0 | Criação inicial da story | PM Agent "John" |

---

## Dev Agent Record

*Esta seção será preenchida pelo agente de desenvolvimento durante a implementação*

### Agent Model Used
*TBD*

### Debug Log References
*TBD*

### Completion Notes List
*TBD*

### File List
*TBD*

---

## QA Results

*Esta seção será preenchida pelo agente de QA após revisão da implementação*